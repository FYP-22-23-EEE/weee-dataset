{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from envyaml import EnvYAML\n",
    "import pandas as pd\n",
    "import tsfel\n",
    "import datetime\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "def to_csv(df, path):\n",
    "    df.to_csv(path, index=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E4 dataset directories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "VAR_ENV = EnvYAML(\"../../../../env.yaml\")\n",
    "path_list = [os.path.join(\"../../../..\", VAR_ENV[\"dataset.path\"], VAR_ENV[\"dataset.version\"],\n",
    "                          f\"P{i:02d}\", \"EARBUDS\") for i in range(1, VAR_ENV[\"dataset.participants\"] + 1)]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all CSV files to same type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/v1/P01/EARBUDS/P01-imu-left.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287061/2666777277.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/v1/P01/EARBUDS/P01-imu-right.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287061/2666777277.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/v1/P02/EARBUDS/P02-imu-right.csv\n",
      "../../../../data/v1/P03/EARBUDS/P03-imu-right.csv\n",
      "../../../../data/v1/P04/EARBUDS/P04-imu-right.csv\n",
      "../../../../data/v1/P05/EARBUDS/P05-imu-right.csv\n",
      "../../../../data/v1/P06/EARBUDS/P06-imu-right.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_287061/2666777277.py:19: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_temp = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/v1/P07/EARBUDS/P07-imu-right.csv\n",
      "../../../../data/v1/P07/EARBUDS/P07-imu-left.csv\n",
      "../../../../data/v1/P08/EARBUDS/P08-imu-right.csv\n",
      "../../../../data/v1/P08/EARBUDS/P08-imu-left.csv\n",
      "../../../../data/v1/P09/EARBUDS/P09-imu-left.csv\n",
      "../../../../data/v1/P09/EARBUDS/P09-imu-right.csv\n",
      "../../../../data/v1/P10/EARBUDS/P10-imu-right.csv\n",
      "../../../../data/v1/P10/EARBUDS/P10-imu-left.csv\n",
      "../../../../data/v1/P11/EARBUDS/P11-imu-right.csv\n",
      "../../../../data/v1/P11/EARBUDS/P11-imu-left.csv\n",
      "../../../../data/v1/P12/EARBUDS/P12-imu-right.csv\n",
      "../../../../data/v1/P12/EARBUDS/P12-imu-left.csv\n",
      "../../../../data/v1/P13/EARBUDS/P13-imu-left.csv\n",
      "../../../../data/v1/P13/EARBUDS/P13-imu-right.csv\n",
      "../../../../data/v1/P14/EARBUDS/P14-imu-left.csv\n",
      "../../../../data/v1/P14/EARBUDS/P14-imu-right.csv\n",
      "../../../../data/v1/P15/EARBUDS/P15-imu-right.csv\n",
      "../../../../data/v1/P15/EARBUDS/P15-imu-left.csv\n",
      "../../../../data/v1/P16/EARBUDS/P16-imu-right.csv\n",
      "../../../../data/v1/P16/EARBUDS/P16-imu-left.csv\n",
      "../../../../data/v1/P17/EARBUDS/P17-imu-right.csv\n",
      "../../../../data/v1/P17/EARBUDS/P17-imu-left.csv\n"
     ]
    }
   ],
   "source": [
    "study_information = pd.read_csv(os.path.join(\"../../../..\", VAR_ENV[\"dataset.path\"], VAR_ENV[\"dataset.version\"],\"Study_Information.csv\"))\n",
    "\n",
    "for path in path_list:\n",
    "\n",
    "    # dataset manipulation\n",
    "\n",
    "    removing_files = glob.glob(os.path.join(path, '*_initial.csv'), recursive=True)\n",
    "\n",
    "    for file_path in removing_files:\n",
    "        os.remove(file_path)\n",
    "\n",
    "    file_path_list = glob.glob(os.path.join(path, f'P{path_list.index(path)+1:02d}-imu-*.csv'), recursive=True)\n",
    "\n",
    "    for file_path in file_path_list:\n",
    "        print(file_path)\n",
    "\n",
    "        # deciding the side of the earbud\n",
    "        side = 'right' if 'right' in file_path else 'left'\n",
    "\n",
    "        # read file\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "\n",
    "        if(path_list.index(path) == 0 or path_list.index(path) == 5):\n",
    "\n",
    "            # get start time from the first row as a unix millisecond timestamp\n",
    "            starting_time = datetime.datetime.strptime(df_temp.loc[0, 'timestamp'], \"%Y-%m-%d %H:%M:%S\").timestamp() * 1000\n",
    "\n",
    "            # drop first row\n",
    "            df_temp.drop(df_temp.index[0], inplace=True)\n",
    "\n",
    "            # change data type of the timestamp column to numeric\n",
    "            df_temp['timestamp'] = pd.to_numeric(df_temp['timestamp'])\n",
    "\n",
    "            # add start time to every other row's timestamp\n",
    "            df_temp['timestamp'] +=  starting_time\n",
    "\n",
    "            # convert to datetime\n",
    "            timestamps = [datetime.datetime.fromtimestamp(df_temp.loc[i+1, 'timestamp']/1000) for i in range(len(df_temp))]\n",
    "\n",
    "        else:\n",
    "            # convert to datetime\n",
    "            timestamps = [datetime.datetime.fromtimestamp(df_temp.loc[i, 'timestamp']/1000, datetime.timezone(datetime.timedelta(hours=0))) for i in range(len(df_temp))]\n",
    "        df_temp.drop('timestamp', axis=1, inplace=True)\n",
    "        df_temp.insert(0, 'timestamp', timestamps, True)\n",
    "\n",
    "        # change data type of the timestamp column to numeric\n",
    "        df_temp['timestamp'] = pd.to_datetime(df_temp['timestamp'])\n",
    "\n",
    "        # sort whole dataframe by time stamp\n",
    "        df_temp = df_temp.sort_values(by=['timestamp'])\n",
    "\n",
    "        # remove rows until sessions starting according to study information\n",
    "        breaking_index = 0\n",
    "        for i in range (1,len(df_temp)):\n",
    "            if (datetime.datetime.fromisoformat(str(df_temp[\"timestamp\"][i]).split('.')[0].split('+')[0]) < datetime.datetime.fromisoformat(study_information[\"Start_Sit\"][path_list.index(path)])):\n",
    "                breaking_index += 1\n",
    "            else:\n",
    "                break\n",
    "        df_temp.drop(df_temp.index[:breaking_index], inplace=True)\n",
    "            \n",
    "        # saving\n",
    "        to_csv(df_temp, os.path.join(\"../../../..\", VAR_ENV[\"dataset.path\"], VAR_ENV[\"dataset.version\"], f\"P{path_list.index(path)+1:02d}\", \"EARBUDS\", f'{file_path.split(\"/\")[-1].split(\".\")[0]}_initial.csv'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../../data/v1/P01/EARBUDS/P01-imu-left_initial.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 50\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m# df_temp['gyro_x_avg'] = 0\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m# df_temp['gyro_y_avg'] = 0\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[39m# df_temp['gyro_z_avg'] = 0\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[1;32m     48\u001b[0m \u001b[39m# calculate moving windows\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(df_temp)\u001b[39m-\u001b[39mmoving_window_size):\n\u001b[0;32m---> 50\u001b[0m     df_temp\u001b[39m.\u001b[39;49mloc[i\u001b[39m+\u001b[39;49mmoving_window_size\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39macc_x_avg\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m df_temp\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mmoving_window_size][\u001b[39m'\u001b[39m\u001b[39macc_x\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\u001b[39m/\u001b[39mmoving_window_size\n\u001b[1;32m     51\u001b[0m     df_temp\u001b[39m.\u001b[39mloc[i\u001b[39m+\u001b[39mmoving_window_size\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39macc_y_avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_temp\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mmoving_window_size][\u001b[39m'\u001b[39m\u001b[39macc_y\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\u001b[39m/\u001b[39mmoving_window_size\n\u001b[1;32m     52\u001b[0m     df_temp\u001b[39m.\u001b[39mloc[i\u001b[39m+\u001b[39mmoving_window_size\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m'\u001b[39m\u001b[39macc_z_avg\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_temp\u001b[39m.\u001b[39miloc[i:i\u001b[39m+\u001b[39mmoving_window_size][\u001b[39m'\u001b[39m\u001b[39macc_z\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum()\u001b[39m/\u001b[39mmoving_window_size\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/indexing.py:1767\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1765\u001b[0m taker[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m   1766\u001b[0m reindexers \u001b[39m=\u001b[39m {i: (labels, taker)}\n\u001b[0;32m-> 1767\u001b[0m new_obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_reindex_with_indexers(\n\u001b[1;32m   1768\u001b[0m     reindexers, allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m   1769\u001b[0m )\n\u001b[1;32m   1770\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_mgr \u001b[39m=\u001b[39m new_obj\u001b[39m.\u001b[39m_mgr\n\u001b[1;32m   1771\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_maybe_update_cacher(clear\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/generic.py:5355\u001b[0m, in \u001b[0;36mNDFrame._reindex_with_indexers\u001b[0;34m(self, reindexers, fill_value, copy, allow_dups)\u001b[0m\n\u001b[1;32m   5352\u001b[0m     indexer \u001b[39m=\u001b[39m ensure_platform_int(indexer)\n\u001b[1;32m   5354\u001b[0m \u001b[39m# TODO: speed up on homogeneous DataFrame objects (see _reindex_multi)\u001b[39;00m\n\u001b[0;32m-> 5355\u001b[0m new_data \u001b[39m=\u001b[39m new_data\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m   5356\u001b[0m     index,\n\u001b[1;32m   5357\u001b[0m     indexer,\n\u001b[1;32m   5358\u001b[0m     axis\u001b[39m=\u001b[39;49mbaxis,\n\u001b[1;32m   5359\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m   5360\u001b[0m     allow_dups\u001b[39m=\u001b[39;49mallow_dups,\n\u001b[1;32m   5361\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m   5362\u001b[0m )\n\u001b[1;32m   5363\u001b[0m \u001b[39m# If we've made a copy once, no need to make another one\u001b[39;00m\n\u001b[1;32m   5364\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/internals/managers.py:753\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    751\u001b[0m     parent \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mall_none(\u001b[39m*\u001b[39mnew_refs) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 753\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    754\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[1;32m    755\u001b[0m             indexer,\n\u001b[1;32m    756\u001b[0m             axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    757\u001b[0m             fill_value\u001b[39m=\u001b[39m(\n\u001b[1;32m    758\u001b[0m                 fill_value \u001b[39mif\u001b[39;00m fill_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m blk\u001b[39m.\u001b[39mfill_value\n\u001b[1;32m    759\u001b[0m             ),\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    762\u001b[0m     ]\n\u001b[1;32m    763\u001b[0m     new_refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     parent \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/internals/managers.py:754\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    751\u001b[0m     parent \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mall_none(\u001b[39m*\u001b[39mnew_refs) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\n\u001b[1;32m    752\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    753\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[0;32m--> 754\u001b[0m         blk\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    755\u001b[0m             indexer,\n\u001b[1;32m    756\u001b[0m             axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    757\u001b[0m             fill_value\u001b[39m=\u001b[39;49m(\n\u001b[1;32m    758\u001b[0m                 fill_value \u001b[39mif\u001b[39;49;00m fill_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m blk\u001b[39m.\u001b[39;49mfill_value\n\u001b[1;32m    759\u001b[0m             ),\n\u001b[1;32m    760\u001b[0m         )\n\u001b[1;32m    761\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    762\u001b[0m     ]\n\u001b[1;32m    763\u001b[0m     new_refs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     parent \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/internals/blocks.py:880\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    877\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    881\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[1;32m    882\u001b[0m )\n\u001b[1;32m    884\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m    885\u001b[0m \u001b[39m#  this assertion\u001b[39;00m\n\u001b[1;32m    886\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m (axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m new_mgr_locs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/array_algos/take.py:163\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    158\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    160\u001b[0m func \u001b[39m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    161\u001b[0m     arr\u001b[39m.\u001b[39mndim, arr\u001b[39m.\u001b[39mdtype, out\u001b[39m.\u001b[39mdtype, axis\u001b[39m=\u001b[39maxis, mask_info\u001b[39m=\u001b[39mmask_info\n\u001b[1;32m    162\u001b[0m )\n\u001b[0;32m--> 163\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    165\u001b[0m \u001b[39mif\u001b[39;00m flip_order:\n\u001b[1;32m    166\u001b[0m     out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g_multiplier = 0.061/1000\n",
    "dps_multiplier = 17.5/1000\n",
    "\n",
    "moving_window_size = 100 * 60\n",
    "for path in path_list[:1]:\n",
    "\n",
    "    # dataset manipulation\n",
    "\n",
    "    file_path_list = glob.glob(os.path.join(path, '*_initial.csv'), recursive=True)\n",
    "\n",
    "    for file_path in file_path_list:\n",
    "        print(file_path)\n",
    "        # deciding the side of the earbud\n",
    "        side = 'right' if 'right' in file_path else 'left'\n",
    "\n",
    "        # read file\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "\n",
    "        # transform device accelerometer output to g\n",
    "        df_temp[\"acc_x\"] = df_temp[\"ax\"]*g_multiplier\n",
    "        df_temp[\"acc_y\"] = df_temp[\"ay\"]*g_multiplier\n",
    "        df_temp[\"acc_z\"] = df_temp[\"az\"]*g_multiplier\n",
    "\n",
    "        # transform device gyroscope output to dps\n",
    "        df_temp[\"gyro_x\"] = df_temp[\"gx\"]*dps_multiplier\n",
    "        df_temp[\"gyro_y\"] = df_temp[\"gy\"]*dps_multiplier\n",
    "        df_temp[\"gyro_z\"] = df_temp[\"gz\"]*dps_multiplier\n",
    "\n",
    "        # initialize new columns for central moving averages\n",
    "        df_temp['acc_x_avg'] = 0\n",
    "        df_temp['acc_y_avg'] = 0\n",
    "        df_temp['acc_z_avg'] = 0\n",
    "        # df_temp['gyro_x_avg'] = 0\n",
    "        # df_temp['gyro_y_avg'] = 0\n",
    "        # df_temp['gyro_z_avg'] = 0\n",
    "\n",
    "        # calculate moving windows\n",
    "        for i in range(0, len(df_temp)-moving_window_size):\n",
    "            df_temp.loc[i+moving_window_size//2, 'acc_x_avg'] = df_temp.iloc[i:i+moving_window_size]['acc_x'].sum()/moving_window_size\n",
    "            df_temp.loc[i+moving_window_size//2, 'acc_y_avg'] = df_temp.iloc[i:i+moving_window_size]['acc_y'].sum()/moving_window_size\n",
    "            df_temp.loc[i+moving_window_size//2, 'acc_z_avg'] = df_temp.iloc[i:i+moving_window_size]['acc_z'].sum()/moving_window_size\n",
    "            print(f'{i*100/len(df_temp)}%')\n",
    "\n",
    "        # drop previous columns\n",
    "        df_temp.drop('acc_x', inplace=True, axis=1)\n",
    "        df_temp.drop('acc_y', inplace=True, axis=1)\n",
    "        df_temp.drop('acc_z', inplace=True, axis=1)\n",
    "        df_temp.drop('ax', inplace=True, axis=1)\n",
    "        df_temp.drop('ay', inplace=True, axis=1)\n",
    "        df_temp.drop('az', inplace=True, axis=1)\n",
    "        df_temp.drop('gx', inplace=True, axis=1)\n",
    "        df_temp.drop('gy', inplace=True, axis=1)\n",
    "        df_temp.drop('gz', inplace=True, axis=1)\n",
    "\n",
    "        print(df_temp.iloc[2999])\n",
    "\n",
    "        # # saving\n",
    "        to_csv(df_temp, os.path.join(\"../../../..\",\n",
    "               VAR_ENV[\"dataset.path\"], VAR_ENV[\"dataset.version\"], f\"P{path_list.index(path)+1:02d}\", \"EARBUDS\", f\"modified_imu_{side}.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unnecessary rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/indexes/range.py:391\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
      "\u001b[1;32m    390\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;32m--> 391\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_range\u001b[39m.\u001b[39;49mindex(new_key)\n",
      "\u001b[1;32m    392\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in range\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)\n",
      "Cell \u001b[0;32mIn[29], line 9\u001b[0m\n",
      "\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m (\u001b[39m1\u001b[39m,\u001b[39mlen\u001b[39m(df_temp)):\n",
      "\u001b[1;32m      8\u001b[0m     \u001b[39mprint\u001b[39m(i)\n",
      "\u001b[0;32m----> 9\u001b[0m     \u001b[39mif\u001b[39;00m (datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mfromisoformat(\u001b[39mstr\u001b[39m(df_temp[\u001b[39m\"\u001b[39;49m\u001b[39mtimestamp\u001b[39;49m\u001b[39m\"\u001b[39;49m][i])\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]) \u001b[39m>\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mfromisoformat(study_information[\u001b[39m\"\u001b[39m\u001b[39mStart_Sit\u001b[39m\u001b[39m\"\u001b[39m][path_list\u001b[39m.\u001b[39mindex(path)])):\n",
      "\u001b[1;32m     10\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[1;32m     11\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n",
      "\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n",
      "\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n",
      "\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n",
      "\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n",
      "\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n",
      "\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n",
      "\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n",
      "\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n",
      "\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n",
      "\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/weee-dataset-l4oCkYpH/lib/python3.10/site-packages/pandas/core/indexes/range.py:393\u001b[0m, in \u001b[0;36mRangeIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n",
      "\u001b[1;32m    391\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_range\u001b[39m.\u001b[39mindex(new_key)\n",
      "\u001b[1;32m    392\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[0;32m--> 393\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n",
      "\u001b[1;32m    394\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;32m    395\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n",
      "\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "for path in path_list[:1]:\n",
    "    # dataset manipulation\n",
    "\n",
    "    file_path_list = glob.glob(os.path.join(path, '*_initial.csv'), recursive=True)\n",
    "\n",
    "    for file_path in file_path_list:\n",
    "        # deciding the side of the earbud\n",
    "        side = 'right' if 'right' in file_path else 'left'\n",
    "\n",
    "        df_temp = pd.read_csv(file_path)\n",
    "        df_temp.drop(df_temp.index[:moving_window_size//2-1], inplace=True)\n",
    "        df_temp.drop(df_temp.index[len(df_temp)-moving_window_size//2-1:], inplace=True)\n",
    "\n",
    "        to_csv(df_temp, os.path.join(\"../../../..\",\n",
    "              VAR_ENV[\"dataset.path\"], VAR_ENV[\"dataset.version\"], f\"P{path_list.index(path)+1:02d}\", \"EARBUDS\", f\"modified_0_rows_removed_IMU_ACC_{side}.csv\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "weee-dataset-l4oCkYpH",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1367f830a7667d8dfdf66ab5a664543b559253404065f1d8c1c9d2a5c327239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
